{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Die ROC-Curve - Beurteilung binärer Classifier\n",
    "### Einführungsbeispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "#Die tatsächliche Klassenzugehörigkeit (also 0 oder 1) ist hier wiedergegeben:\n",
    "y = np.array([0,0,0,0,0,1,1,1,1,1]) \n",
    "# Gegeben seien Vorhersagen eines Modells: 0.5 sei die Entscheidungsgrenze: \n",
    "scores = np.array([0.45, 0.43, 0.55, 0.45, 0.55, 0.55, 0.6, 0.52, 0.51, 0.6])\n",
    "#y_test_pred = (scores >= 0.9)\n",
    "print('Das Modell sagt: ' + str(y_test_pred))\n",
    "print('Tatsächlich:     ' + str(y == 1))\n",
    "# ...um 0.5 herum gibt es also FP's und FN's, was mit der ROC-Curve gezeigt wird:\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=1)\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Schöner in Seaborn.....\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "# y: tatsächlich              \n",
    "conf_mat = pd.crosstab(y, y_test_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(conf_mat, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die ROC-Curve an einem Beispiel-Modell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../classification.csv\")\n",
    "\n",
    "# Wenn du ein paar Spalten vorab aus den Daten entfernen\n",
    "# df = df.drop(\"Spaltenname\", axis = 1)\n",
    "\n",
    "# Wenn du eine kategorische Variable in mehrere Spalten umwandeln\n",
    "# möchtest, kannst du das mit folgendem Code tun:\n",
    "# df = pd.get_dummies(df, columns = [\"Spaltenname\"])\n",
    "\n",
    "df.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Welche Spalten sollen zur Vorhersage verwendet werden\n",
    "X = df[[\"age\", \"interest\"]].values\n",
    "\n",
    "# Oder: Die Spalte \"success\" soll nicht zur Vorhersage verwendet werden:\n",
    "# X = df.drop(\"success\", axis = 1).values\n",
    "\n",
    "y = df[\"success\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Achtung!!! - Entweder Naiver-Bayes oder....\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Achtung!!! - ....oder Logistic Regression ausführen...\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "# das liefert aber nur 0en und 1en\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict_proba() liefert nun Wahrscheinlichkeitswerte\n",
    "#[....[Wahrscheinlichkeit0,  Wahrscheinlichkeit1], ....]\n",
    "model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_pred, pos_label=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.roc_curve?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Die Veranschaulichung der ROC-Curve mit mehr oder weniger aussagekräftigen Verteilungen von Score-Werten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "from sklearn import metrics\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "n = 300\n",
    "negative = np.random.normal(0, 0.1, n) #Gauss-Verteilung mit Mittelwert, Standardabweichung, Anzahl n Datenpunkte\n",
    "positive = np.random.normal(0, 0.1, n) #Gauss-Verteilung mit Mittelwert, Standardabweichung, Anzahl n Datenpunkte\n",
    "\n",
    "def hist_model(y_negativ, y_positiv):\n",
    "    fig, axs = plt.subplots(1,3, figsize=(15, 5))\n",
    "    fig.tight_layout(pad=5.0) #Abstand der Subplots\n",
    "    #fig.suptitle('Titel')\n",
    "    \n",
    "    axs[0].set_title('Daten binärer Klassenzugehörigkeit')\n",
    "    axs[0].set_xlim([0, 1])\n",
    "    neg = negative+y_negativ\n",
    "    pos = positive+y_positiv\n",
    "    X = np.concatenate((neg, pos))\n",
    "    y = np.concatenate(( np.zeros(n), np.ones(n) ))\n",
    "    entscheidungsgrenze = (y_positiv + y_negativ) / 2\n",
    "    y_pred = X >= entscheidungsgrenze\n",
    "    axs[0].hist(neg, bins = (int)(n/10), color='red',  alpha = 0.5)\n",
    "    axs[0].hist(pos, bins = (int)(n/10), color='blue', alpha = 0.5)\n",
    "    axs[0].plot([entscheidungsgrenze,entscheidungsgrenze], [0,10], color='black')\n",
    "    axs[0].text(entscheidungsgrenze, 0.44, 'Entscheidungsgrenze', color='black', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)\n",
    "    axs[0].text(entscheidungsgrenze, 0.39, 'des Modells', color='black', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)\n",
    "\n",
    "    axs[0].set_xlabel(\"Score-Wert des Modells\", \n",
    "           #family='serif', \n",
    "           #color='r', \n",
    "           weight='normal', \n",
    "           size = 16,\n",
    "           labelpad = 6)\n",
    "    axs[0].set_ylabel(\"Anzahl\", \n",
    "           #family='serif', \n",
    "           #color='r', \n",
    "           weight='normal', \n",
    "           size = 16,\n",
    "           labelpad = 6)\n",
    "    axs[0].text(0.5, 0.9, 'Rot: negativ', color='red', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)\n",
    "    axs[0].text(0.5, 0.85, 'Blau: positiv', color='blue', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)\n",
    "    axs[0].text(0.5, 0.8, 'Violett: uneindeutig', color='purple', horizontalalignment='center', verticalalignment='center', transform=axs[0].transAxes)\n",
    "\n",
    "    axs[1].set_title('ROC-Kurve')   \n",
    "    axs[1].set_xlabel(\"P(TP)\", \n",
    "           #family='serif', \n",
    "           #color='r', \n",
    "           weight='normal', \n",
    "           size = 16,\n",
    "           labelpad = 6)\n",
    "    axs[1].set_ylabel(\"P(FP)\", \n",
    "           #family='serif', \n",
    "           #color='r', \n",
    "           weight='normal', \n",
    "           size = 16,\n",
    "           labelpad = 6)\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y, X, pos_label=1)\n",
    "    axs[1].plot(fpr, tpr)\n",
    "    auc = roc_auc_score(y, y_pred)\n",
    "    axs[1].text(0.5, 0.5, 'AUC-Score: {auc:.3f}'.format(auc=auc), horizontalalignment='center', verticalalignment='center', transform=axs[1].transAxes)\n",
    "\n",
    "    axs[2].set_title('Confusion-Matrix')\n",
    "    conf_mat = pd.crosstab(y, y_pred, rownames=['Actual'], colnames=['Predicted'])\n",
    "    sn.heatmap(conf_mat, annot=True, ax=axs[2]) \n",
    "    \n",
    "interact(hist_model, y_negativ = widgets.FloatSlider(value=0.35,\n",
    "                                               min=0,\n",
    "                                               max=1.0,\n",
    "                                               step=0.05),\n",
    "                    y_positiv = widgets.FloatSlider(value=0.65,\n",
    "                                               min=0,\n",
    "                                               max=1.0,\n",
    "                                               step=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
