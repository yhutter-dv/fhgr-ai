{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervized Learning\n",
    "### Das Ellbow-Kriterium zur Bestimmung der optimalen Anzahl von Clustern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Wir nehmen den berühmten IRIS-Datensatz....\n",
    "df = pd.read_csv(\"../iris.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Jetzt tun wir mal so, wir wüssten nicht, dass es drei verschiedene Schwertlilienarten gäbe...\n",
    "data = df[['SepalLengthCm','SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\n",
    "data.head()\n",
    "# \"data\" enthält also keine Information über die Klassenzugehörigkeit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir ermitteln die Distanzen der Objekte, die mit kMeans einem jeweiligen Cluster zugewiesen wurden.\n",
    "import numpy as np\n",
    "sse = {}\n",
    "for k in range(2, 10):  # Wir probieren alle Clustergrößen von 1 bis 10 aus....\n",
    "    kmeans = KMeans(n_clusters=k, max_iter=1000).fit(data)\n",
    "    sse[k] = kmeans.inertia_ /100 # Inertia: Sum of distances of samples to their closest cluster center\n",
    "   \n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Anzahl der Cluster\")\n",
    "plt.ylabel(\"Summe der Distanzen der Samples (SSE)\")\n",
    "\n",
    "# Wo ist der Ellenbogen? - Dort wo die Kurve beginnt parallel zur X-Achse linear zu werden.  \n",
    "#(O.K. - Wir wissen ja, dass \"3\" die richtige Lösung ist: Setosa, Virginica, Versicolor)\n",
    "plt.scatter(3, sse[3], color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fehlersummen über alle Cluster-Anzahlen von 1 bis 10\n",
    "sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entwicklung der Fehlersumme in %\n",
    "for s in sse.values():\n",
    "    print(100* s / sse[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab der 3.  ist es fast linear... Wir wissen, dass es eigentlich 3 Cluster sind, \n",
    "# ...das Ellbow-Kreterium lässt aber 4 Cluster fast plausibler erscheinen! - Mist!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
